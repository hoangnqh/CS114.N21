{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers.tokenization_utils_base import TruncationStrategy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "import json\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import underthesea # Thư viện tách từ\n",
    "from pyvi import ViTokenizer, ViPosTagger # thư viện NLP tiếng Việt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import dump\n",
    "from pprint import pprint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'X_train[0]'\n",
      "'Kêu 1 cặp 2 cái đặt x5 mà giao đc 5 cái shop làm ăn kiểu gì v'\n"
     ]
    }
   ],
   "source": [
    "# Đọc dữ liệu từ file Excel\n",
    "file_path = \"Book1.xlsx\"\n",
    "data_frame = pd.read_excel(file_path, header=None)\n",
    "\n",
    "# Truy cập vào cột thứ nhất và thứ hai\n",
    "labels = data_frame.iloc[:, 0].tolist()\n",
    "reviews = data_frame.iloc[:, 1].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, labels, test_size=0.2, random_state=20520051, shuffle=True)\n",
    "pprint(\"X_train[0]\")\n",
    "pprint(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🙂👿😠😡🙁😒😫😕😩😣😟😭😢😖😔😞☹️🤧🤒😷🤕😵🤢🤠🤡👹👺👻💀👽😰😨😧🤥😈🙃👎🤬👋😌😏😬💩😓😤😮‍💨😑\n",
      "😀😊😉😍😘😗😙🤗😚😛😝😜😋🤑😎😇♥️❤️💛💚💙💜🖤💖💝🤩🥰😅💞💋🤗😋🥳\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tichcuc = \"sản phẩm tốt chất lượng tốt \"\n",
    "tieucuc = \"sản phẩm tệ kém chất lượng \"\n",
    "with open('icon_tieu_cuc.txt', 'r', encoding='utf-8') as file:\n",
    "    icon_tieu_cuc = file.read()\n",
    "print(icon_tieu_cuc)\n",
    "with open('icon_tich_cuc.txt', 'r', encoding='utf-8') as file:\n",
    "    icon_tich_cuc = file.read()\n",
    "print(icon_tich_cuc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm chuẩn hoá câu\n",
    "def standardize_data(row):\n",
    "    # Icon biểu tượng\n",
    "    for val in row:\n",
    "        if val in icon_tich_cuc:\n",
    "            row = tichcuc + row\n",
    "        if val in icon_tieu_cuc:\n",
    "            row = tieucuc + row\n",
    "    # Xoá hết những cái không phải chữ và số\n",
    "    row =  re.sub(r\"[^\\w\\s]\", \" \", row)\n",
    "    \n",
    "    # # Xóa dấu chấm, phẩy, hỏi ở cuối câu\n",
    "    # row = re.sub(r\"[\\.,\\?]+$-\", \"\", row)\n",
    "    # # Xóa tất cả dấu chấm, phẩy, chấm phẩy, chấm thang, ... trong câu\n",
    "    # row = row.replace(\",\", \" \").replace(\".\", \" \") \\\n",
    "    #     .replace(\";\", \" \").replace(\"“\", \" \") \\\n",
    "    #     .replace(\":\", \" \").replace(\"”\", \" \") \\\n",
    "    #     .replace('\"', \" \").replace(\"'\", \" \") \\\n",
    "    #     .replace(\"!\", \" \").replace(\"?\", \" \") \\\n",
    "    #     .replace(\"-\", \" \").replace(\"?\", \" \")\n",
    "    # # Nếu có nhiều khoảng trắng thì rút gọn còn 1\n",
    "    row = row.replace('\\n',\" \")\n",
    "    row = re.sub(r\"\\s+\", \" \", row)\n",
    "    # Đưa hết về chữ thường\n",
    "    row = row.strip().lower()\n",
    "    str = \"\"\n",
    "    str += row[0]\n",
    "    for i in range(1, len(row)):\n",
    "        if row[i] != row[i - 1]:\n",
    "            str += row[i]\n",
    "    # pprint(str)\n",
    "    # print(ascii(row[16]))\n",
    "    # Chuyển thành dạng không dấu\n",
    "    # str = unidecode(str)\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm load danh sách các từ vô nghĩa: lắm, ạ, à, bị, vì..\n",
    "sw = []\n",
    "with open(\"vietnamese-stopwords - Copy.txt\", encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines:\n",
    "    sw.append(line.replace(\"\\n\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# model_trans = AutoModel.from_pretrained(\"Fsoft-AIC/videberta-xsmall\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"Fsoft-AIC/videberta-xsmall\")\n",
    "\n",
    "# model_trans = AutoModel.from_pretrained(\"Fsoft-AIC/videberta-base\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"Fsoft-AIC/videberta-base\")\n",
    "\n",
    "# model_trans = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "\n",
    "# model_trans = AutoModel.from_pretrained(\"vinai/phobert-large\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-large\")\n",
    "\n",
    "model_trans = AutoModel.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tiền xử lý dữ liệu sử dụng PhoBERT   \n",
    "\n",
    "\n",
    "# Hàm tạo ra bert features\n",
    "def make_bert_features(v_text):\n",
    "    v_tokenized = []\n",
    "    max_len = 150 # Mỗi câu dài tối đa 200 từ\n",
    "    for i_text in v_text:\n",
    "        # print(\"Đang xử lý line = \", i_text)\n",
    "        # Chuẩn hóa\n",
    "        \n",
    "        i_text = i_text.replace(\"\\n\",\" \")\n",
    "        i_text = standardize_data(i_text)\n",
    "\n",
    "        # # Phân thành từng từ\n",
    "        # line = underthesea.word_tokenize(i_text)\n",
    "\n",
    "        # # Lọc các từ vô nghĩa\n",
    "        # # filtered_sentence = [w for w in line if not w in sw]\n",
    "        # filtered_sentence = line\n",
    "\n",
    "        # # Ghép lại thành câu như cũ sau khi lọc\n",
    "        # line = \" \".join(filtered_sentence[:100])\n",
    "        # line = underthesea.word_tokenize(line, format=\"text\")\n",
    "        line = ViTokenizer.tokenize(i_text)[:150]\n",
    "    \n",
    "\n",
    "        # print(\"Word segment  = \", line)\n",
    "        # Tokenize bởi BERT\n",
    "        line = tokenizer.encode(line)\n",
    "        v_tokenized.append(line)\n",
    "\n",
    "    padded = []\n",
    "    # Chèn thêm số 1 vào cuối câu nếu như không đủ từ hoặc xóa nếu dư\n",
    "    for line in v_tokenized:\n",
    "        if len(line) < max_len:\n",
    "            padded.append(line + [1] * (max_len - len(line)))\n",
    "        else:\n",
    "            padded.append(line[: max_len])\n",
    "    padded = np.array(padded)\n",
    "\n",
    "    # print('padded:', padded[0])\n",
    "    # print('len padded:', padded.shape)\n",
    "\n",
    "    # Đánh dấu các từ thêm vào = 0 để không tính vào quá trình lấy features\n",
    "    attention_mask = np.where(padded == 1, 0, 1)\n",
    "    # print('attention mask:', attention_mask[0])\n",
    "\n",
    "    # Chuyển thành tensor\n",
    "    padded = torch.tensor(padded).to(torch.long)\n",
    "    print(\"Padd = \",padded.size())\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "    # Lấy features dầu ra từ BERT\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model_trans(input_ids= padded, attention_mask=attention_mask)\n",
    "\n",
    "    v_features = last_hidden_states[0][:, 0, :].numpy()\n",
    "    print(v_features.shape)\n",
    "    return v_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padd =  torch.Size([1948, 150])\n",
      "(1948, 768)\n"
     ]
    }
   ],
   "source": [
    "X_train = make_bert_features(X_train)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huấn luyện mô hình SVM\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padd =  torch.Size([487, 150])\n",
      "(487, 768)\n"
     ]
    }
   ],
   "source": [
    "# Chuẩn bị dữ liệu kiểm tra\n",
    "X_test = make_bert_features(X_test)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8752260397830017\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán nhãn cho tập kiểm tra\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best prarams: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "F1 score: 0.92573402417962\n"
     ]
    }
   ],
   "source": [
    "# Tune model bằng grid search\n",
    "parameters = {\n",
    "                'kernel': ('linear', 'rbf'), \n",
    "                'C': [0.5, 1, 2, 4], \n",
    "                'gamma': ['scale']#, 0.125, 0.25, 0.5, 1, 2, 4]\n",
    "            }\n",
    "\n",
    "clf = GridSearchCV(SVC(), param_grid=parameters,  cv = 5, scoring='f1', n_jobs=-1)\n",
    "grid_search = clf.fit(X_train, y_train)\n",
    "\n",
    "# best prarams\n",
    "print('best prarams:', clf.best_params_)\n",
    "\n",
    "svm_best_model = grid_search.best_estimator_\n",
    "y_pred = svm_best_model.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "# dump(svm_model, 'save_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.9116607773851589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán nhãn cho tập kiểm tra\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best Score: 0.9165439438601615\n",
      "F1 score: 0.9263157894736843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.90024343 0.89766168 0.91654394 0.91645879 0.9160616\n",
      "        nan 0.90077923 0.90613499 0.90053059 0.90022751 0.9033783\n",
      "        nan 0.8815877  0.89530175 0.88924228 0.88935487 0.89406021]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "# Thiết lập lưới tham số cần tìm kiếm\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['lbfgs', 'liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Tìm kiếm lưới các tham số tốt nhất\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# In ra bộ tham số tốt nhất và đánh giá mô hình\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Đánh giá mô hình trên dữ liệu kiểm tra\n",
    "y_pred = grid_search.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Best score:  0.8910752157897355\n",
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Định nghĩa các tham số cần tinh chỉnh và giá trị để thử nghiệm\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "\n",
    "# Tạo đối tượng Grid Search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv = 5, scoring='f1', n_jobs=-1)\n",
    "\n",
    "# Tiến hành Grid Search trên dữ liệu huấn luyện\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# In ra các thông số tốt nhất từ Grid Search\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Dự đoán nhãn cho dữ liệu kiểm tra sử dụng mô hình tốt nhất\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Đánh giá độ chính xác\n",
    "accuracy = f1_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9204152249134949\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# Khởi tạo mô hình XGBClassifier\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Huấn luyện mô hình trên tập huấn luyện\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán nhãn cho tập kiểm tra\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Đánh giá độ chính xác của mô hình\n",
    "accuracy = f1_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBClassifier()\n",
    "\n",
    "# # Định nghĩa siêu tham số và giá trị để tinh chỉnh\n",
    "# param_grid = {\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'learning_rate': [0.1, 0.01, 0.001],\n",
    "#     'n_estimators': [100, 500, 1000]\n",
    "# }\n",
    "\n",
    "# # Sử dụng Grid Search để tìm siêu tham số tốt nhất\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='f1', cv=3, n_jobs=4)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Lấy siêu tham số tốt nhất và tạo mô hình với siêu tham số đó\n",
    "# best_params = grid_search.best_params_\n",
    "# model = XGBClassifier(**best_params)\n",
    "\n",
    "# # Huấn luyện mô hình trên toàn bộ tập huấn luyện\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Dự đoán nhãn cho tập kiểm tra\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Đánh giá độ chính xác của mô hình\n",
    "# accuracy = f1_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
