{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Đồ án cuối kì**\n",
        "### **Mã lớp:** CS114.N21\n",
        "\n",
        "### **Giảng viên:** Phạm Nguyễn Trường An\n",
        "### **Đề tài:** Phân loại đánh giá của khách hàng trên Shopee\n",
        "\n",
        "### **Thành viên nhóm H2O:**\n",
        "- Nguyễn Quốc Huy Hoàng - 20520051\n",
        "- Ngô Quang Vinh - 19522523"
      ],
      "metadata": {
        "id": "wctNkvsTMzBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import các thư viện cần thiết"
      ],
      "metadata": {
        "id": "RdD2F4FQNRMr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EqEU6VcpyXx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from transformers.tokenization_utils_base import TruncationStrategy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "import json\n",
        "import requests\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import underthesea # Thư viện tách từ\n",
        "from pyvi import ViTokenizer, ViPosTagger # thư viện NLP tiếng Việt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "from joblib import dump\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-i_QqeMpyX0"
      },
      "source": [
        "## Xử lý dữ liệu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Đọc dữ liệu sau đó chia làm 2 tập train/test"
      ],
      "metadata": {
        "id": "8s5RM8cXOEQU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wv51jxrCpyX1",
        "outputId": "c28fb44d-b0d2-4428-8285-8f7e549aa8f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'X_train[0]'\n",
            "'Kêu 1 cặp 2 cái đặt x5 mà giao đc 5 cái shop làm ăn kiểu gì v'\n"
          ]
        }
      ],
      "source": [
        "# Đọc dữ liệu từ file Excel\n",
        "file_path = \"Book1.xlsx\"\n",
        "data_frame = pd.read_excel(file_path, header=None)\n",
        "\n",
        "# Truy cập vào cột thứ nhất và thứ hai\n",
        "labels = data_frame.iloc[:, 0].tolist()\n",
        "reviews = data_frame.iloc[:, 1].tolist()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reviews, labels, test_size=0.2, random_state=20520051, shuffle=True)\n",
        "pprint(\"X_train[0]\")\n",
        "pprint(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGzMWnikpyX2",
        "outputId": "24d8e86e-be83-4bdb-e069-3580dae9493c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🙂👿😠😡🙁😒😫😕😩😣😟😭😢😖😔😞☹️🤧🤒😷🤕😵🤢🤠🤡👹👺👻💀👽😰😨😧🤥😈🙃👎🤬👋😌😏😬💩😓😤😮‍💨😑\n",
            "😀😊😉😍😘😗😙🤗😚😛😝😜😋🤑😎😇♥️❤️💛💚💙💜🖤💖💝🤩🥰😅💞💋🤗😋🥳\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tichcuc = \"sản phẩm tốt chất lượng tốt \"\n",
        "tieucuc = \"sản phẩm tệ kém chất lượng \"\n",
        "with open('icon_tieu_cuc.txt', 'r', encoding='utf-8') as file:\n",
        "    icon_tieu_cuc = file.read()\n",
        "print(icon_tieu_cuc)\n",
        "with open('icon_tich_cuc.txt', 'r', encoding='utf-8') as file:\n",
        "    icon_tich_cuc = file.read()\n",
        "print(icon_tich_cuc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chuẩn hóa dữ liệu"
      ],
      "metadata": {
        "id": "FjV3568wNdeS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkcYPYP-pyX3"
      },
      "outputs": [],
      "source": [
        "# Hàm chuẩn hoá câu\n",
        "def standardize_data(row):\n",
        "    # Icon biểu tượng\n",
        "    for val in row:\n",
        "        if val in icon_tich_cuc:\n",
        "            row = tichcuc + row\n",
        "        if val in icon_tieu_cuc:\n",
        "            row = tieucuc + row\n",
        "    # Xoá hết những cái không phải chữ và số\n",
        "    row =  re.sub(r\"[^\\w\\s]\", \" \", row)\n",
        "\n",
        "    # # Xóa dấu chấm, phẩy, hỏi ở cuối câu\n",
        "    # row = re.sub(r\"[\\.,\\?]+$-\", \"\", row)\n",
        "    # # Xóa tất cả dấu chấm, phẩy, chấm phẩy, chấm thang, ... trong câu\n",
        "    # row = row.replace(\",\", \" \").replace(\".\", \" \") \\\n",
        "    #     .replace(\";\", \" \").replace(\"“\", \" \") \\\n",
        "    #     .replace(\":\", \" \").replace(\"”\", \" \") \\\n",
        "    #     .replace('\"', \" \").replace(\"'\", \" \") \\\n",
        "    #     .replace(\"!\", \" \").replace(\"?\", \" \") \\\n",
        "    #     .replace(\"-\", \" \").replace(\"?\", \" \")\n",
        "    # # Nếu có nhiều khoảng trắng thì rút gọn còn 1\n",
        "    row = row.replace('\\n',\" \")\n",
        "    row = re.sub(r\"\\s+\", \" \", row)\n",
        "    # Đưa hết về chữ thường\n",
        "    row = row.strip().lower()\n",
        "    str = \"\"\n",
        "    str += row[0]\n",
        "    for i in range(1, len(row)):\n",
        "        if row[i] != row[i - 1]:\n",
        "            str += row[i]\n",
        "    # pprint(str)\n",
        "    # print(ascii(row[16]))\n",
        "    # Chuyển thành dạng không dấu\n",
        "    # str = unidecode(str)\n",
        "    return str"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lấy danh sách stop word của tiếng Việt"
      ],
      "metadata": {
        "id": "gwTEov1bNhS2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAYdoQcwpyX3"
      },
      "outputs": [],
      "source": [
        "# Hàm load danh sách các từ vô nghĩa: lắm, ạ, à, bị, vì..\n",
        "sw = []\n",
        "with open(\"vietnamese-stopwords - Copy.txt\", encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "for line in lines:\n",
        "    sw.append(line.replace(\"\\n\",\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chuyển văn bảng thành dạng vetor đặc trưng"
      ],
      "metadata": {
        "id": "4sbyP5agNnuo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4oQTnempyX4",
        "outputId": "02541962-5a04-4c8d-f0f1-c865a01a99e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# model_trans = AutoModel.from_pretrained(\"Fsoft-AIC/videberta-xsmall\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"Fsoft-AIC/videberta-xsmall\")\n",
        "\n",
        "# model_trans = AutoModel.from_pretrained(\"Fsoft-AIC/videberta-base\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"Fsoft-AIC/videberta-base\")\n",
        "\n",
        "model_trans = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
        "\n",
        "# model_trans = AutoModel.from_pretrained(\"vinai/phobert-large\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-large\")\n",
        "\n",
        "# model_trans = AutoModel.from_pretrained(\"vinai/phobert-base-v2\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aio-du7xpyX4"
      },
      "outputs": [],
      "source": [
        "# Hàm tạo ra bert features\n",
        "def make_bert_features(v_text):\n",
        "    v_tokenized = []\n",
        "    max_len = 150 # Mỗi câu dài tối đa 200 từ\n",
        "    for i_text in v_text:\n",
        "        # print(\"Đang xử lý line = \", i_text)\n",
        "        # Chuẩn hóa\n",
        "\n",
        "        i_text = i_text.replace(\"\\n\",\" \")\n",
        "        i_text = standardize_data(i_text)\n",
        "\n",
        "        # # Phân thành từng từ\n",
        "        # line = underthesea.word_tokenize(i_text)\n",
        "\n",
        "        # # Lọc các từ vô nghĩa\n",
        "        # # filtered_sentence = [w for w in line if not w in sw]\n",
        "        # filtered_sentence = line\n",
        "\n",
        "        # # Ghép lại thành câu như cũ sau khi lọc\n",
        "        # line = \" \".join(filtered_sentence[:100])\n",
        "        # line = underthesea.word_tokenize(line, format=\"text\")\n",
        "        line = ViTokenizer.tokenize(i_text)[:150]\n",
        "\n",
        "\n",
        "        # print(\"Word segment  = \", line)\n",
        "        # Tokenize bởi BERT\n",
        "        line = tokenizer.encode(line)\n",
        "        v_tokenized.append(line)\n",
        "\n",
        "    padded = []\n",
        "    # Chèn thêm số 1 vào cuối câu nếu như không đủ từ hoặc xóa nếu dư\n",
        "    for line in v_tokenized:\n",
        "        if len(line) < max_len:\n",
        "            padded.append(line + [1] * (max_len - len(line)))\n",
        "        else:\n",
        "            padded.append(line[: max_len])\n",
        "    padded = np.array(padded)\n",
        "\n",
        "    # print('padded:', padded[0])\n",
        "    # print('len padded:', padded.shape)\n",
        "\n",
        "    # Đánh dấu các từ thêm vào = 0 để không tính vào quá trình lấy features\n",
        "    attention_mask = np.where(padded == 1, 0, 1)\n",
        "    # print('attention mask:', attention_mask[0])\n",
        "\n",
        "    # Chuyển thành tensor\n",
        "    padded = torch.tensor(padded).to(torch.long)\n",
        "    print(\"Padd = \",padded.size())\n",
        "    attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "    # Lấy features dầu ra từ BERT\n",
        "    with torch.no_grad():\n",
        "        last_hidden_states = model_trans(input_ids= padded, attention_mask=attention_mask)\n",
        "\n",
        "    v_features = last_hidden_states[0][:, 0, :].numpy()\n",
        "    print(v_features.shape)\n",
        "    return v_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5M0oBU-pyX4",
        "outputId": "1fdc47e2-e42b-4e4a-f3e1-724b85eb5d0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padd =  torch.Size([1948, 150])\n"
          ]
        }
      ],
      "source": [
        "# Xử lý dữ liệu tập train\n",
        "X_train = make_bert_features(X_train)\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqEDTFx3pyX5",
        "outputId": "3a778701-bfe0-4bb9-c15d-8a920ecc8613"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padd =  torch.Size([487, 150])\n",
            "(487, 384)\n"
          ]
        }
      ],
      "source": [
        "# Xử lý dữ liệu tập test\n",
        "X_test = make_bert_features(X_test)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mô hình phân lớp\n"
      ],
      "metadata": {
        "id": "4Re_Va9PNs9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "Im4ERO91N51l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Xây dựng và huấn luyện mô hình"
      ],
      "metadata": {
        "id": "f1w_vdAVN7rs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkNkvU7_pyX5"
      },
      "outputs": [],
      "source": [
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dự đoán và đánh giá"
      ],
      "metadata": {
        "id": "tMwj5dnoOPuT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ4EyLffpyX5",
        "outputId": "4ae846ab-7153-446f-fe42-73601974b8be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 score: 0.7334200260078023\n"
          ]
        }
      ],
      "source": [
        "# Dự đoán nhãn cho tập kiểm tra\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Đánh giá mô hình\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"F1 score:\", f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tinh chỉnh mô hình"
      ],
      "metadata": {
        "id": "7X8T1MGhOSl7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRgsSQ9QpyX5",
        "outputId": "024f9049-24b7-4fc9-dbb4-f5e9ee38fb77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best prarams: {'C': 0.5, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "F1 score: 0.7334200260078023\n"
          ]
        }
      ],
      "source": [
        "# Tune model bằng grid search\n",
        "parameters = {\n",
        "                'kernel': ('linear', 'rbf'),\n",
        "                'C': [0.5, 1, 2, 4],\n",
        "                'gamma': ['scale']#, 0.125, 0.25, 0.5, 1, 2, 4]\n",
        "            }\n",
        "\n",
        "clf = GridSearchCV(SVC(), param_grid=parameters,  cv = 5, scoring='f1', n_jobs=-1)\n",
        "grid_search = clf.fit(X_train, y_train)\n",
        "\n",
        "# best prarams\n",
        "print('best prarams:', clf.best_params_)\n",
        "\n",
        "svm_best_model = grid_search.best_estimator_\n",
        "y_pred = svm_best_model.predict(X_test)\n",
        "\n",
        "# Đánh giá mô hình\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"F1 score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwI5EKyfpyX6",
        "outputId": "9a8a431c-b8ba-44ca-9899-c211b73ef430"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['save_model.joblib']"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save model\n",
        "# dump(svm_model, 'save_model.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "-RuqPKnqOVjI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Xây dựng và huấn luyện vô hình"
      ],
      "metadata": {
        "id": "QWMYXH0oOdaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "S2oH3ZGhOc9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dự đoán và đánh giá"
      ],
      "metadata": {
        "id": "S3SBF7-SO1Mw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DQIjMv3pyX6",
        "outputId": "96d38851-55c2-4ffd-faa8-47f0fd7a1fe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 score: 0.7334200260078023\n"
          ]
        }
      ],
      "source": [
        "# Dự đoán nhãn cho tập kiểm tra\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"F1 score:\", f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tinh chỉnh mô hình"
      ],
      "metadata": {
        "id": "xReHDcWUO3Zf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng2LVkGNpyX6",
        "outputId": "4965df1b-5e09-4e9c-f5a9-1a6dd2bcd3b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Score: 0.7213650115962603\n",
            "F1 score: 0.7334200260078023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "15 fits failed out of a total of 90.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.72136501 0.72136501 0.72136501 0.72136501 0.72136501\n",
            "        nan 0.72136501 0.72136501 0.72136501 0.72136501 0.72136501\n",
            "        nan 0.72136501 0.72136501 0.72136501 0.72136501 0.72136501]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = LogisticRegression()\n",
        "\n",
        "# Thiết lập lưới tham số cần tìm kiếm\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['lbfgs', 'liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# Tìm kiếm lưới các tham số tốt nhất\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# In ra bộ tham số tốt nhất và đánh giá mô hình\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)\n",
        "\n",
        "# Đánh giá mô hình trên dữ liệu kiểm tra\n",
        "y_pred = grid_search.predict(X_test)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"F1 score:\", f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Radom Forest"
      ],
      "metadata": {
        "id": "Bd-qqLEnO6wD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Q1OuqN8pyX6",
        "outputId": "6fb0b47d-eb6d-4f7f-d27f-edb1a1be31d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters:  {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Best score:  0.7213650115962603\n",
            "Accuracy: 0.7334200260078023\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Định nghĩa các tham số cần tinh chỉnh và giá trị để thử nghiệm\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "\n",
        "# Tạo đối tượng Grid Search\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv = 5, scoring='f1', n_jobs=-1)\n",
        "\n",
        "# Tiến hành Grid Search trên dữ liệu huấn luyện\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# In ra các thông số tốt nhất từ Grid Search\n",
        "print(\"Best parameters: \", grid_search.best_params_)\n",
        "print(\"Best score: \", grid_search.best_score_)\n",
        "\n",
        "# Dự đoán nhãn cho dữ liệu kiểm tra sử dụng mô hình tốt nhất\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Đánh giá độ chính xác\n",
        "accuracy = f1_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGB"
      ],
      "metadata": {
        "id": "YZhiyzxePAqv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Tack31RpyX6",
        "outputId": "aa380b6d-816f-4ddb-fedf-d007b18ca404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8939929328621908\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "# Khởi tạo mô hình XGBClassifier\n",
        "model = XGBClassifier()\n",
        "\n",
        "# Huấn luyện mô hình trên tập huấn luyện\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Dự đoán nhãn cho tập kiểm tra\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Đánh giá độ chính xác của mô hình\n",
        "accuracy = f1_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdIUnTdhpyX6"
      },
      "outputs": [],
      "source": [
        "# model = XGBClassifier()\n",
        "\n",
        "# # Định nghĩa siêu tham số và giá trị để tinh chỉnh\n",
        "# param_grid = {\n",
        "#     'max_depth': [3, 5, 7],\n",
        "#     'learning_rate': [0.1, 0.01, 0.001],\n",
        "#     'n_estimators': [100, 500, 1000]\n",
        "# }\n",
        "\n",
        "# # Sử dụng Grid Search để tìm siêu tham số tốt nhất\n",
        "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='f1', cv=3, n_jobs=4)\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# # Lấy siêu tham số tốt nhất và tạo mô hình với siêu tham số đó\n",
        "# best_params = grid_search.best_params_\n",
        "# model = XGBClassifier(**best_params)\n",
        "\n",
        "# # Huấn luyện mô hình trên toàn bộ tập huấn luyện\n",
        "# model.fit(X_train, y_train)\n",
        "\n",
        "# # Dự đoán nhãn cho tập kiểm tra\n",
        "# y_pred = model.predict(X_test)\n",
        "\n",
        "# # Đánh giá độ chính xác của mô hình\n",
        "# accuracy = f1_score(y_test, y_pred)\n",
        "# print(\"Accuracy:\", accuracy)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}